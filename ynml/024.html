<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<HTML>
   <HEAD>
      <TITLE>My first HTML document</TITLE>
      <style rel="stylesheet" type="text/css">
body {
 font-size: 25px;
 
 margin-top: 50px;
    margin-bottom: 50px;
    margin-right: 80px;
    margin-left: 80px;
    
    padding-top: 50px;
    padding-bottom: 50px;
    padding-right: 80px;
    padding-left: 80px;
    
    line-height:1.6em
}
</style>
      <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    "HTML-CSS" : {
        availableFonts : ["STIX"],
        preferredFont : "STIX",
        webFont : "STIX-Web",
        imageFont : null
    }
});
</script>
     <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js" type="text/javascript">    
    MathJax.Hub.Config({
        HTML: ["input/TeX","output/HTML-CSS"],
        TeX: { extensions: ["AMSmath.js","AMSsymbols.js"], 
               equationNumbers: { autoNumber: "AMS" } },
        extensions: ["tex2jax.js"],
        jax: ["input/TeX","output/HTML-CSS"],
        tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                   displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                   processEscapes: true },
        "HTML-CSS": { availableFonts: ["TeX"],
                      linebreaks: { automatic: true } }
    });
</script>
   </HEAD>
   <BODY>
024. Basic of applying deep learning methodology with Keras<br/>
<xmp>
@
# Run bmi-create.py to create bmi.csv

import random
# This is a method which returns calculated 3 labels of BMI
def calc_bmi(h, w):
    bmi = w / (h/100) ** 2
    if bmi < 18.5: 
        return "thin"
    if bmi < 25: 
        return "normal"
    return "fat"

# I prepare a csv file to contain data
fp = open("bmi.csv", "w", encoding="utf-8")
fp.write("height,weight,label\r\n")
# I generate random data
# I create cnt dictionary and each value of key is initialized by 0
cnt = {"thin":0, "normal":0, "fat":0}
# I will iterate from 0 to 20000
for i in range(20000):
    # I generate random number for height
    h = random.randint(120,200)
    # I generate random number for weight
    w = random.randint(35, 80)
    # I find bmi label among "normal", "fat", "thin" from above 2 values
    label = calc_bmi(h, w)
    # I increate one value for the corresponding label in the cnt dictionary
    cnt[label] += 1
    # I write contents into bmi.csv in the following format
    fp.write("{0},{1},{2}\r\n".format(h, w, label))
# I close file strean    
fp.close()
print("file generation is completed : ", cnt)


@
# Now, I will make the keras expecting model to learn as following steps
# 1. I load modules I need to process this task
# 1. I load bmi.csv file data
# 1. I create a model which is similar to learning methods like fit() and predict() which are what we've learned
# For learning
# For predicting
# For evaluating

from keras.module import Sequential
from keras.layers.core import Dense, Dropout, Activation
from keras.callbacks import EarlyStopping
import pandas as pd
import numpy as np


# I process features train data
# [
#     # I normalize data by dividing them, resulting values from 0 to 1
#     [height/200, weight/100],
#     [height/200, weight/100]
# ]

# # I process labels of train data
# [
#     # Each label will be converted as one-hot-encoding
#     # [1,0,0], [0,1,0], [0,0,1]
#     "thin",
#     "normal",
#     "fat"

# ]

@
# I load bmi.csv file
csv = pd.read_csv("d://chromedown//bmi.csv")
# I bring all data from weight column and I divide them all by 100, 200 to normalize
csv["weight"] /= 100 
csv["height"] /= 200

# I make bmi_class dictionary and I convert each label into one-hot-encoding value in list
bmi_class = 
{
    "thin":[1,0,0],
    "normal":[0,1,0],
    "fat":[0,0,1]
}

# I make 20000 lists which has 3 spaces inside of one list
# For example,
# [
#     [0,0,0],
#     [0,0,0],
#     ...,
#     [0,0,0]
# ]
y = np.empty((20000, 3))

# I write index and value in frond area of tuple
# from the data which I bring from csv["label"] by using enumerate(csv["label"])
for i, v in enumerate(csv["label"]):
    y[i] = bmi_class[v]
    # I will use following output as label for corresponding feature train data
    # output:
    # [
    #     [0 0 1]
    #     [1 0 0]
    #     ...
    # ]

# I convert data from csv file into matrix
x = csv[["weight", "height"]].as_matrix()

# I divide data into train data and test data
x_train, y_train = x[1:15001], y[1:15001]
x_test, y_test = x[15001:20001], y[15001:20001]

# I use Sequential model and I compose layers and you get composed model
model = Sequential()
model.add(Dense(512, input_shape=(2,)))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.1))
model.add(Dense(3))
model.add(Activation('softmax'))
# I actually make model
model.compile("rmsprop", "categorical_crossentropy", metrics=["accuracy"])

# For learning
# model.fit(x_train, y_train)
# For learning to enhance performance by passing addtional arguments
model.fit
(
    x_train, 
    y_train,
    # batch_size is page quantity of training book
    # I want to enhance the page quantity of training book which is trained by model in one sequence of training, so expecting model can train more
    # For this, I change default value 30 to 100
    batch_size=100,
    # 1 epoch means expecting model finishes one training book
    # So, I make expecting model to finish 20 training books
    nb_epoch=20,
    validation_split=0.1,
    callbacks=[EarlyStopping(monitor='val_loss', patience=2)],
    verbose=1
)
# For predicting 
model.predict()
# For evaluating
score = model.evaluate(x_test, y_test)
# score is returned as list
print("score of loss:", score[0])
print("score of accuracy:", score[1])

@
# Reference keras document on http://keras.io/modules/Sequential
# For compile(), we pass 
# 1 argument: optimizer, 
# 2 argument: loss, 
# 3 argument: metrics(default=none), if you use this, you can get better evalution from training and testing

# You can see various kind of optimizers
# You will try to use RMSprop optimizer

# You can see various kind of losses
# You will try to use categorical_crossentropy loss

@
# run this python file
# and you can see tensorflow running in the backend
# you can see loss value and accuracy value in the middle of training

</xmp>
   </BODY>
</HTML>
